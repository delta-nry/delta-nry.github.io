---
layout: post
title: The Goto Situation
---

In the old days before vendor standardization, people who purchased their newfangled "personal computers" had two choices of programming languages: BASIC or the computer's native machine code. One of these first personal computers was the Apple II, and those who chose to program BASIC on one were obligated to use a particular statement: goto. Programs were typed line by line, with users also manually typing in the line numbers of their code. Other than being a nuisance to manage, these line numbers were the labels that goto operations would jump execution flow to. An example Apple II BASIC program is as follows:

{% highlight basic %}
1  REM    PRINTS "0" TO THE SCREEN
10 X = 0
20 IF X = 1 THEN GOTO 60
30 PRINT X
40 X = 1
50 GOTO 20
60 END
{% endhighlight %}

Although goto is sensible in the preceding example, complexity can quickly escalate with larger programs. Since goto allows program flow to jump to any line in the program source code, tracking the "logical flow" of your code can become incredibly difficult. It can lead to "spaghetti code", which is very similar to a [Choose Your Own Adventure](http://en.wikipedia.org/wiki/Choose_Your_Own_Adventure) book. If you've read one of these books before, you remember how you were instructed to switch to some seemingly random pages depending on what decisions in the story you would make. This arbitrary behavior illustrates the problems that goto can have on your programs.

Due to goto potentially leading to incomprehensible code, Edsger Dijkstra in a [specific paper](http://www.cs.utexas.edu/~EWD/transcriptions/EWD02xx/EWD215.html) strongly discouraged its use, with the opinion that goto should be removed from all high level languages, if not including machine code as well. However, goto still exists in many languages, including C. Fortunately, goto in C is restricted to function scope rather than file/program scope and is nowhere near as dangerous as it is in other languages. Nevertheless, the "de-facto" C programming language book [The C Programming Language](http://en.wikipedia.org/wiki/The_C_Programming_Language) still strongly discourages its use. The sole example of goto that the writers mention is using it to escape from a series of deeply nested loops (although one could argue that one should not need to create so many loops in the first place). But goto has more practical applications than this in C, such as state machine design, error handling and code cleanup. Note that the latter two cases are covered by different features in other languages (exceptions, garbage collection, RAII, etc.), but this is the usual way to do those actions in C. If one considers C to be a "low level language" (which I personally disagree with), then perhaps goto has a place in low level languages, but what about high level languages? Surely we shouldn't give unsuspecting programmers more rope to hang themselves with? These sentiments indicate a more intrinsic problem: encouraging code simplicity through less or more programming language functionality.

In structured programming, goto is unnecessary to create correct programs. However, judicious use of goto can lead to better structured and intuitive code. I believe that the goto statement should be placed in the same boat as language features such as class friendship and multiple inheritance: in most cases they are unneeded and unnecessarily complicate your code, but they are optimal in specific situations. So perhaps Dijkstra's suggestion of removing goto is mistaken, at least for the more tightly controlled versions used today. However, he does give legitimate reasons against its use, and I agree that goto should be avoided whenever possible and only be used in very optimal situations. One goal of programming is to express the most functionality with the smallest and most intuitive amount of code necessary. In almost every case this means not using goto, but in certain cases it is indeed the best option available.

One may argue that even when optimally used, using goto still sets a bad precedent for its users and thus should not exist to prevent its abuse. While I agree that preventing novices from bad programming practices can be beneficial, this comes at the expense of stifling expert programmers. Perhaps we should ask ourselves how many features (such as goto) should we add to a language without making it too overwhelming and complex? There is no surefire way to determine this. I suggest that features should be added in regards to how often they are predicted to be used. If we predict that a language feature such as goto would not be used often, then it is reasonable to omit it from the language. Admittedly, this is nowhere near a rigorous argument. Perhaps an "uncommon" language feature ends up being used more than its intended "common" counterpart. Or maybe a "useless" language feature ends up being pivotal for some extremely specific yet critical future development initiatives. Other people will inevitably have different opinions on this matter, and I stress that there is no right or wrong answer to this problem. The "less vs. more" decision is simply a trade-off, which we unfortunately have to deal with as programmers. Ultimately, dealing with this trade-off is up to language designers to decide, but together we can help them make the best out of this ambiguous situation.

